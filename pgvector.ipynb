{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e10e08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (4.38.2)\n",
      "Requirement already satisfied: psycopg2 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (2.9.9)\n",
      "Requirement already satisfied: numpy in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (1.26.2)\n",
      "Requirement already satisfied: boto3 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (1.34.98)\n",
      "Requirement already satisfied: torch in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (2.2.1)\n",
      "Requirement already satisfied: scikit-learn in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: matplotlib in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (3.8.2)\n",
      "Requirement already satisfied: nltk in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (3.8.1)\n",
      "Collecting sentence-transformers\n",
      "  Obtaining dependency information for sentence-transformers from https://files.pythonhosted.org/packages/76/2c/bd95032aeb087b0706596af0a4518c4bfe0439a1bb149048ece18b617766/sentence_transformers-2.7.0-py3-none-any.whl.metadata\n",
      "  Downloading sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: filelock in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.98 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from boto3) (1.34.98)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from boto3) (0.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from torch) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.99)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from scikit-learn) (3.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from matplotlib) (4.46.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: click in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from nltk) (8.1.6)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.98->boto3) (1.26.16)\n",
      "Requirement already satisfied: six>=1.5 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/antoine/.pyenv/versions/3.10.11/envs/shinobi/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-2.7.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers psycopg2 numpy boto3 torch scikit-learn matplotlib nltk sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef964d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from multiprocessing import Pool\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "import torch\n",
    "import psycopg2\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d081c4bf",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ba0050",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/bart-large\"\n",
    "tokenizer_name = \"facebook/bart-large\"\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "# Load the model\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c632971",
   "metadata": {},
   "source": [
    "# Remove stopwords to reduce noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf58305d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961ab957",
   "metadata": {},
   "source": [
    "# Define a list of movie titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e062e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "with open(os.path.join(current_directory, \"movies.json\"), \"r\") as f:\n",
    "    movies = json.load(f)\n",
    "\n",
    "movies_data = []\n",
    "for movie in movies[\"films\"][\"film\"]:\n",
    "\n",
    "    roles = movie.get(\"role\", [])\n",
    "    if isinstance(roles, dict):  # If 'roles' is a dictionary, make it a single-item list\n",
    "        roles = [roles]\n",
    "\n",
    "    # Extract actor information\n",
    "    actors = []\n",
    "    for role in roles:\n",
    "        actor_info = role.get(\"acteur\", {})\n",
    "        if \"__text\" in actor_info:\n",
    "            actors.append(actor_info[\"__text\"])\n",
    "\n",
    "    movies_data.append({\n",
    "        \"title\": movie.get(\"titre\", \"\"),\n",
    "        \"year\": movie.get(\"annee\", \"\"),\n",
    "        \"country\": movie.get(\"pays\", \"\"),\n",
    "        \"language\": movie.get(\"langue\", \"\"),\n",
    "        \"duration\": movie.get(\"duree\", \"\"),\n",
    "        \"summary\": movie.get(\"synopsis\", \"\"),\n",
    "        \"genre\": movie.get(\"genre\", \"\"),\n",
    "        \"director\": movie.get(\"realisateur\", {\"__text\": \"\"}).get(\"__text\", \"\"),\n",
    "        \"writers\": movie.get(\"scenariste\", []),\n",
    "        \"actors\": actors,\n",
    "        \"poster\": movie.get(\"affiche\", \"\"),\n",
    "        \"id\": movie.get(\"id\", \"\")\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f824df81",
   "metadata": {},
   "source": [
    "# Generate embeddings for movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa8efb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.4649309\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Load a large model\n",
    "model = SentenceTransformer('all-MiniLM-L12-v2')\n",
    "\n",
    "# Example sentences\n",
    "sentences = [\"This is a fox.\", \"This is a dog.\"]\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "cosine_similarity = np.dot(embeddings[0], embeddings[1]) / (np.linalg.norm(embeddings[0]) * np.linalg.norm(embeddings[1]))\n",
    "print(\"Cosine Similarity:\", cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0734623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    # Example preprocessing step simplified for demonstration\n",
    "    tokens = text.split()\n",
    "    # Assuming stopwords are already loaded to avoid loading them in each process\n",
    "    stopwords_set = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word.lower() not in stopwords_set]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200c77c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding(text):\n",
    "    movie_texts = [\n",
    "        f\"{preprocess(movie['title'])} {movie['year']} {' '.join(movie['genre'])} \"\n",
    "        f\"{' '.join(movie['actors'])} {movie['director']} \"\n",
    "        f\"{preprocess(movie['summary'])} {movie['country']}\"\n",
    "        for movie in movies_data\n",
    "    ]\n",
    "    inputs = tokenizer(movie_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039cca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = generate_embedding(movies_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064217e8",
   "metadata": {},
   "source": [
    "# Create connection to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaf92bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(database=\"admin\", host=\"localhost\", user=\"admin\", password=\"admin\", port=\"5432\")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940a6588",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e59c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_database():\n",
    "    cur.execute('DROP TABLE IF EXISTS movies')\n",
    "    cur.execute('''\n",
    "        CREATE TABLE movies (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            title TEXT NOT NULL,\n",
    "            actors TEXT,\n",
    "            year INTEGER,\n",
    "            country TEXT,\n",
    "            language TEXT,\n",
    "            duration INTEGER,\n",
    "            summary TEXT,\n",
    "            genre TEXT[],\n",
    "            director TEXT,\n",
    "            scenarists TEXT[],\n",
    "            poster TEXT,\n",
    "            embedding vector(1024)\n",
    "        );\n",
    "    ''')\n",
    "    conn.commit()\n",
    "\n",
    "setup_database()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cd0378",
   "metadata": {},
   "source": [
    "# Insert movie titles and their embeddings into the 'movies' table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44254a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_movies(movie_data, embeddings):\n",
    "    for movie, embedding in zip(movie_data, embeddings):\n",
    "        # Joining actors into a single string separated by commas\n",
    "        actor_names = ', '.join(movie['actors'])\n",
    "        # Convert list of genres into a PostgreSQL array format\n",
    "        genre_array = '{' + ', '.join([f'\"{g}\"' for g in movie['genre']]) + '}'\n",
    "        # Convert list of scenarists into a PostgreSQL array format\n",
    "        scenarist_array = '{' + ', '.join([f'\"{s}\"' for s in movie['writers']]) + '}'\n",
    "        # Convert embedding to a string properly formatted as a list\n",
    "        embedding_str = '[' + ', '.join(map(str, embedding)) + ']'\n",
    "\n",
    "        cur.execute('''\n",
    "            INSERT INTO movies (title, actors, year, country, language, duration, summary, genre, director, scenarists, poster, embedding)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        ''', (\n",
    "            movie['title'], actor_names, movie['year'], movie['country'], movie['language'],\n",
    "            movie['duration'], movie['summary'], genre_array, movie['director'],\n",
    "            scenarist_array, movie['poster'], embedding_str  # Insert the string representation of embedding\n",
    "        ))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7161589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_movies(movies_data, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5f3b3e",
   "metadata": {},
   "source": [
    "# Finding similar movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84795f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_embedding(title):\n",
    "    cur.execute('SELECT embedding FROM movies WHERE title = %s', (title,))\n",
    "    result = cur.fetchone()\n",
    "    if result:\n",
    "        embedding_str = result[0]\n",
    "        embedding = [float(x) for x in embedding_str.strip('[]').split(',')]\n",
    "        return np.array(embedding, dtype=float).reshape(1, -1)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def find_similar_movies(title, threshold=0.5, return_n=25, distance_function='cosine_similarity'):\n",
    "    query_embedding = get_query_embedding(title)\n",
    "    if query_embedding is None:\n",
    "        print(f\"No embedding found for the movie titled '{title}'.\")\n",
    "        return []\n",
    "\n",
    "    cur.execute('SELECT title, embedding FROM movies')\n",
    "    rows = cur.fetchall()\n",
    "\n",
    "    embeddings = []\n",
    "    movie_titles = []\n",
    "    for other_title, embedding_str in rows:\n",
    "        if other_title != title:\n",
    "            embedding = np.array([float(x) for x in embedding_str.strip('[]').split(',')])\n",
    "            embeddings.append(embedding)\n",
    "            movie_titles.append(other_title)\n",
    "\n",
    "    if distance_function == 'cosine_similarity':\n",
    "        distances = pairwise_distances(query_embedding, embeddings, metric='cosine')\n",
    "        similarities = 1 - distances\n",
    "    elif distance_function == 'euclidean_distance':\n",
    "        distances = pairwise_distances(query_embedding, embeddings, metric='euclidean')\n",
    "        similarities = 1 / (1 + distances)\n",
    "    elif distance_function == 'inner_product':\n",
    "        inner_products = np.dot(query_embedding, np.array(embeddings).T)\n",
    "        similarities = inner_products / (np.linalg.norm(query_embedding) * np.linalg.norm(embeddings, axis=1))\n",
    "    elif distance_function == 'hamming_distance':\n",
    "        # convert embeddings to binary\n",
    "        query_binary = np.where(query_embedding > 0, 1, 0)\n",
    "        embeddings_binary = np.where(np.array(embeddings) > 0, 1, 0)\n",
    "        distances = pairwise_distances(query_binary, embeddings_binary, metric='hamming')\n",
    "        similarities = 1 - distances\n",
    "    elif distance_function == 'jaccard_distance':\n",
    "        # convert embeddings to binary\n",
    "        query_binary = np.where(query_embedding > 0, 1, 0)\n",
    "        embeddings_binary = np.where(np.array(embeddings) > 0, 1, 0)\n",
    "        distances = pairwise_distances(query_binary, embeddings_binary, metric='jaccard')\n",
    "        similarities = 1 - distances\n",
    "    else:\n",
    "        print(\"Unsupported distance function.\")\n",
    "        return []\n",
    "\n",
    "    similar_movies = [(movie_titles[i], similarities[0][i]) for i in range(len(movie_titles)) if similarities[0][i] > threshold]\n",
    "    similar_movies.sort(key=lambda x: x[1], reverse=True)\n",
    "    return similar_movies[:return_n]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bdaebb",
   "metadata": {},
   "source": [
    "# SQL query to find similar movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ebaa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_movies_sql(title, threshold=0.1, return_n=10, distance_function='<->'):\n",
    "    allowed_functions = ['<->', '<#>', '<=>', '<+>']  # L2, negative inner product, cosine, L1\n",
    "    if distance_function not in allowed_functions:\n",
    "        print(\"Unsupported distance function.\")\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        cur.execute(f\"\"\"\n",
    "            SELECT title, embedding, embedding {distance_function} (SELECT embedding FROM movies WHERE title = %s) AS distance\n",
    "            FROM movies\n",
    "            WHERE title != %s\n",
    "            ORDER BY distance\n",
    "            LIMIT %s;\n",
    "        \"\"\", (title, title, return_n))\n",
    "\n",
    "        results = cur.fetchall()\n",
    "        if distance_function == '<=>':  # Adjust for cosine similarity\n",
    "            similar_movies = [(row[0], 1 - row[2]) for row in results if (1 - row[2]) > threshold]\n",
    "        else:\n",
    "            similar_movies = [(row[0], row[2]) for row in results if row[2] < threshold]\n",
    "\n",
    "        return similar_movies\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c31e3a8",
   "metadata": {},
   "source": [
    "# Define a query movie title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790cd806",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_movie_title = 'The Incredibles'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56ed3ca",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e47b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_similar_movies(similar_movies, title):\n",
    "    # Prepare data\n",
    "    titles, similarities = zip(*similar_movies)\n",
    "    similarities = [round(sim * 100, 3) for sim in similarities]  # Convert to percentage and round off\n",
    "\n",
    "    # Create a vertical bar chart\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    bars = plt.bar(titles, similarities, color='skyblue')\n",
    "    plt.ylabel('Similarity Score (%)')\n",
    "    plt.title(f\"{title} - Similar Movies for '{query_movie_title}'\")\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e703a5e",
   "metadata": {},
   "source": [
    "# Perform a similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40c6295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For cosine similarity\n",
    "similar_movies = find_similar_movies_sql(query_movie_title, threshold=0.9, return_n=10, distance_function='<=>')\n",
    "plot_similar_movies(similar_movies, 'Cosine Similarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7989e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For cosine similarity\n",
    "similar_movies = find_similar_movies(query_movie_title, threshold=0.9, distance_function='cosine_similarity')\n",
    "plot_similar_movies(similar_movies,'cosine_similarity')\n",
    "\n",
    "\n",
    "# For L2 Distance (Euclidean Distance)\n",
    "similar_movies = find_similar_movies(query_movie_title, threshold=0.1, distance_function='euclidean_distance')\n",
    "plot_similar_movies(similar_movies, 'euclidean_distance')\n",
    "\n",
    "# For Inner Product\n",
    "similar_movies = find_similar_movies(query_movie_title, threshold=0.9, distance_function='inner_product')\n",
    "plot_similar_movies(similar_movies, 'inner_product')\n",
    "\n",
    "# For Hamming Distance\n",
    "similar_movies = find_similar_movies(query_movie_title, threshold=0.1, distance_function='hamming_distance')\n",
    "plot_similar_movies(similar_movies, 'hamming_distance')\n",
    "\n",
    "# For Jaccard Distance\n",
    "similar_movies = find_similar_movies(query_movie_title, threshold=0.1, distance_function='jaccard_distance')\n",
    "plot_similar_movies(similar_movies, 'jaccard_distance')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
