{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (4.42.4)\n",
      "Requirement already satisfied: psycopg2 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (2.9.9)\n",
      "Requirement already satisfied: numpy in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (1.26.4)\n",
      "Requirement already satisfied: boto3 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (1.34.144)\n",
      "Requirement already satisfied: torch in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (2.3.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (1.5.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (3.9.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (3.8.1)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (3.0.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (2.2.2)\n",
      "Requirement already satisfied: langchain in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (0.2.8)\n",
      "Requirement already satisfied: lark in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (1.1.9)\n",
      "Requirement already satisfied: pgvector in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (0.3.1)\n",
      "Requirement already satisfied: psycopg2-binary in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (2.9.9)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (0.7.0)\n",
      "Requirement already satisfied: langchain_community in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (0.2.7)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (0.23.5)\n",
      "Requirement already satisfied: replicate in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (0.28.0)\n",
      "Requirement already satisfied: keras in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (3.4.1)\n",
      "Requirement already satisfied: tf-keras in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (2.17.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.144 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from boto3) (1.34.144)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from boto3) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from torch) (1.13.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: click in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from langchain) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.19 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from langchain) (0.2.20)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from langchain) (0.1.88)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from langchain) (2.7.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: httpx<1,>=0.21.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from replicate) (0.27.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: rich in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from keras) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from keras) (0.3.2)\n",
      "Requirement already satisfied: tensorflow<2.18,>=2.17 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from tf-keras) (2.17.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from botocore<1.35.0,>=1.34.144->boto3) (2.2.2)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.21.0->replicate) (4.4.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.21.0->replicate) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.21.0->replicate) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.21.0->replicate) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.21.0->replicate) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from httpcore==1.*->httpx<1,>=0.21.0->replicate) (0.14.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<0.3.0,>=0.2.19->langchain) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.13.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow<2.18,>=2.17->tf-keras) (2.17.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (4.25.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (70.1.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (2.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (2.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras) (2.18.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.19->langchain) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (0.43.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers psycopg2 numpy boto3 torch scikit-learn matplotlib nltk sentence-transformers pandas langchain lark pgvector psycopg2-binary tiktoken langchain_community huggingface_hub replicate keras tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\antoi\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from multiprocessing import Pool\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "import torch\n",
    "import psycopg2\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\antoi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"bart\": {\n",
    "        \"model_name\": \"facebook/bart-large\",\n",
    "        \"tokenizer\": AutoTokenizer.from_pretrained(\"facebook/bart-large\", trust_remote_code=True),\n",
    "        \"model\": AutoModel.from_pretrained(\"facebook/bart-large\", trust_remote_code=True)\n",
    "    },\n",
    "    \"gte\": {\n",
    "        \"model_name\": \"Alibaba-NLP/gte-large-en-v1.5\",\n",
    "        \"tokenizer\": AutoTokenizer.from_pretrained(\"Alibaba-NLP/gte-large-en-v1.5\", trust_remote_code=True),\n",
    "        \"model\": AutoModel.from_pretrained(\"Alibaba-NLP/gte-large-en-v1.5\", trust_remote_code=True)\n",
    "    },\n",
    "    \"MiniLM\": {\n",
    "        \"model_name\": 'all-MiniLM-L12-v2',\n",
    "        \"model\": SentenceTransformer('all-MiniLM-L12-v2')\n",
    "    },\n",
    "    \"roberta\": {\n",
    "        \"model_name\": 'sentence-transformers/nli-roberta-large',\n",
    "        \"model\": SentenceTransformer('sentence-transformers/nli-roberta-large')\n",
    "    },\n",
    "    \"e5-large\":{\n",
    "        \"model_name\": 'intfloat/e5-large',\n",
    "        \"tokenizer\": AutoTokenizer.from_pretrained('intfloat/e5-large', trust_remote_code=True),\n",
    "        \"model\": AutoModel.from_pretrained('intfloat/e5-large', trust_remote_code=True)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "with open(os.path.join(current_directory, \"movies.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    movies = json.load(f)\n",
    "\n",
    "movies_data = []\n",
    "for movie in movies[\"films\"][\"film\"]:\n",
    "\n",
    "    roles = movie.get(\"role\", [])\n",
    "    if isinstance(roles, dict):  # If 'roles' is a dictionary, make it a single-item list\n",
    "        roles = [roles]\n",
    "\n",
    "    # Extract actor information\n",
    "    actors = []\n",
    "    for role in roles:\n",
    "        actor_info = role.get(\"acteur\", {})\n",
    "        if \"__text\" in actor_info:\n",
    "            actors.append(actor_info[\"__text\"])\n",
    "\n",
    "    movies_data.append({\n",
    "        \"title\": movie.get(\"titre\", \"\"),\n",
    "        \"year\": movie.get(\"annee\", \"\"),\n",
    "        \"country\": movie.get(\"pays\", \"\"),\n",
    "        \"language\": movie.get(\"langue\", \"\"),\n",
    "        \"duration\": movie.get(\"duree\", \"\"),\n",
    "        \"summary\": movie.get(\"synopsis\", \"\"),\n",
    "        \"genre\": movie.get(\"genre\", \"\"),\n",
    "        \"director\": movie.get(\"realisateur\", {\"__text\": \"\"}).get(\"__text\", \"\"),\n",
    "        \"writers\": movie.get(\"scenariste\", []),\n",
    "        \"actors\": actors,\n",
    "        \"poster\": movie.get(\"poster\", \"\"),\n",
    "        \"id\": movie.get(\"id\", \"\")\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    # Example preprocessing step simplified for demonstration\n",
    "    tokens = text.split()\n",
    "    # Assuming stopwords are already loaded to avoid loading them in each process\n",
    "    stopwords_set = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word.lower() not in stopwords_set]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_embeddings(embeddings):\n",
    "    \"\"\" Normalize the embeddings to unit vectors. \"\"\"\n",
    "    norms = np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "    normalized_embeddings = embeddings / norms\n",
    "    return normalized_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding(movies_data, model_key, normalize=True):\n",
    "    model_config = models[model_key]\n",
    "    if 'tokenizer' in model_config:\n",
    "        # Handle HuggingFace transformer models\n",
    "        movie_texts = [\n",
    "            f\"{preprocess(movie['title'])} {movie['year']} {' '.join(movie['genre'])} \"\n",
    "            f\"{' '.join(movie['actors'])} {movie['director']} \"\n",
    "            f\"{preprocess(movie['summary'])} {movie['country']}\"\n",
    "            for movie in movies_data\n",
    "        ]\n",
    "        inputs = model_config['tokenizer'](movie_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model_config['model'](**inputs)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "    else:\n",
    "        # Handle Sentence Transformers\n",
    "        movie_texts = [\n",
    "            f\"{preprocess(movie['title'])} {movie['year']} {' '.join(movie['genre'])} \"\n",
    "            f\"{' '.join(movie['actors'])} {movie['director']} \"\n",
    "            f\"{preprocess(movie['summary'])} {movie['country']}\"\n",
    "            for movie in tqdm(movies_data, desc=\"Encoding movie texts and generating embeddings\")\n",
    "        ]\n",
    "        embeddings = model_config['model'].encode(movie_texts)\n",
    "\n",
    "    if normalize:\n",
    "        embeddings = normalize_embeddings(embeddings)\n",
    "\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BART embeddings shape: (631, 1024)\n",
      "BART embeddings: [ 0.02980587  0.01581689 -0.0162874  ... -0.00557002 -0.02872263\n",
      " -0.02430014]\n"
     ]
    }
   ],
   "source": [
    "embeddings_bart = generate_embedding(movies_data, 'bart')\n",
    "embeddings_bart = np.array(embeddings_bart)\n",
    "print(\"BART embeddings shape:\", embeddings_bart.shape)\n",
    "print(\"BART embeddings:\", embeddings_bart[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GTE embeddings shape: (631, 1024)\n",
      "GTE embeddings: [ 0.00271679  0.00554605  0.01195132 ...  0.04074343 -0.00983375\n",
      " -0.02142335]\n"
     ]
    }
   ],
   "source": [
    "embeddings_gte = generate_embedding(movies_data, 'gte')\n",
    "embeddings_gte = np.array(embeddings_gte)\n",
    "print(\"GTE embeddings shape:\", embeddings_gte.shape)\n",
    "print(\"GTE embeddings:\", embeddings_gte[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding movie texts and generating embeddings: 100%|██████████| 631/631 [00:00<00:00, 1742.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniLM embeddings shape: (631, 384)\n",
      "MiniLM embeddings: [-7.04024499e-03  6.07011141e-03  1.28376424e-01 -4.50421683e-02\n",
      "  4.66892868e-02  1.10597022e-01  5.81973493e-02  2.08956115e-02\n",
      "  5.28918505e-02  1.14241503e-01 -9.48251039e-02 -4.47546691e-02\n",
      " -1.81262288e-02  1.00744896e-01 -4.28932756e-02  5.07416651e-02\n",
      " -1.08549166e-02  7.32663646e-02 -2.75690667e-02  8.67665000e-03\n",
      " -7.07044676e-02  4.54404689e-02 -3.44804972e-02 -8.39157868e-03\n",
      "  1.86072644e-02 -7.11285621e-02  2.02321932e-02 -5.20065464e-02\n",
      "  3.22543341e-03 -1.99356731e-02  5.68822511e-02 -2.74389284e-03\n",
      " -2.67803054e-02  2.91455481e-02 -4.49042680e-04  5.57996966e-02\n",
      " -1.30207360e-01  1.55704385e-02 -2.01300066e-02 -5.58847636e-02\n",
      "  1.33942459e-02 -3.11912205e-02  1.25691712e-01 -9.65598375e-02\n",
      " -1.80415250e-02 -1.05671175e-02 -5.14752939e-02 -3.55250835e-02\n",
      "  4.20107394e-02  8.37841257e-02 -7.53990039e-02 -2.90898960e-02\n",
      " -1.50384801e-03  8.55621509e-03 -1.42899957e-02 -8.19770396e-02\n",
      " -5.21209054e-02  1.44929150e-02  1.88105796e-02 -2.78054317e-03\n",
      "  3.85414287e-02 -6.85174242e-02  4.61571217e-02  2.19736472e-02\n",
      " -1.11756474e-02  1.46787660e-02 -3.81032974e-02 -6.26537651e-02\n",
      "  8.70189816e-02 -5.95974028e-02 -1.12567760e-01 -2.54905242e-02\n",
      "  3.33829746e-02 -5.34057319e-02 -5.98843358e-02  9.02877674e-02\n",
      "  4.65505980e-02  2.26728674e-02 -8.08471739e-02 -5.89059219e-02\n",
      "  7.92929903e-03 -2.15037609e-03  2.84427982e-02 -4.66949083e-02\n",
      " -4.59704287e-02 -7.72860870e-02  8.76684859e-02 -5.17433248e-02\n",
      " -6.38198629e-02 -2.10230309e-03 -5.24393320e-02 -6.73143417e-02\n",
      "  5.77034280e-02 -1.33280410e-02 -1.11602433e-01 -4.77071330e-02\n",
      "  1.69499323e-01 -2.50264797e-02 -3.37330885e-02  1.06128201e-01\n",
      " -2.18766164e-02  4.19776998e-02  1.25401258e-03  9.08500850e-02\n",
      " -1.91485032e-03 -1.14633240e-01 -9.64627136e-03  3.04795057e-02\n",
      "  4.69674878e-02 -8.81263912e-02 -3.70676704e-02  4.44138348e-02\n",
      " -5.33095635e-02  9.16723069e-03  3.84083800e-02 -8.52247924e-02\n",
      "  1.95138119e-02  3.53913009e-02 -8.09235796e-02 -2.49020234e-02\n",
      "  6.38063625e-02  2.90273409e-03 -7.59678781e-02 -6.42308965e-02\n",
      " -4.28246222e-02 -1.29286990e-01  5.11726539e-04 -1.65296067e-02\n",
      " -2.05808412e-02 -5.50012216e-02  5.25198877e-02 -3.39125432e-02\n",
      "  9.80985463e-02  8.83580185e-03 -8.73862877e-02 -4.35322225e-02\n",
      "  1.39412386e-02  3.08506098e-02  5.84594831e-02  1.77163153e-03\n",
      " -3.48297618e-02 -1.06177749e-02 -2.28768326e-02  4.82883304e-02\n",
      " -4.26815189e-02 -2.83239316e-02  3.09483409e-02  6.27611158e-03\n",
      " -2.86200177e-02  7.69363120e-02  5.54150604e-02 -4.87258770e-02\n",
      "  4.19487953e-02  1.62081104e-02  2.01418567e-02 -5.66205531e-02\n",
      "  7.41562992e-02 -3.12549137e-02 -1.34043377e-02 -3.68052721e-02\n",
      " -5.17619103e-02  2.70205108e-03 -6.41852170e-02 -1.83189251e-02\n",
      " -4.14316803e-02 -5.63548952e-02  7.99072832e-02  1.34132402e-02\n",
      " -2.70476639e-02 -4.50942107e-02  4.19043824e-02  2.29790118e-02\n",
      " -8.94050226e-02  7.52468929e-02 -2.95253540e-03 -5.32483906e-02\n",
      " -4.92520817e-02  9.90465060e-02  4.34273966e-02 -1.01350797e-02\n",
      " -3.23452801e-02  5.57554699e-03 -6.99917674e-02 -6.89559206e-02\n",
      "  2.50736121e-02 -2.25300435e-02 -7.14361528e-03  4.63800505e-02\n",
      "  7.79159963e-02 -1.12750393e-03  7.44970515e-02  6.53346553e-02\n",
      "  5.15046194e-02 -2.63405684e-02  9.08226371e-02 -1.54188657e-02\n",
      "  3.54378708e-02 -3.80420163e-02  4.77117207e-03 -1.08065503e-02\n",
      "  4.69872244e-02 -8.53537917e-02  2.73893550e-02 -9.63758677e-02\n",
      " -2.98996363e-02 -8.52960199e-02 -7.02274591e-02 -2.07165169e-04\n",
      " -3.86640988e-02  6.62176833e-02 -8.12848005e-03 -5.64896911e-02\n",
      "  1.21928146e-02 -1.25271669e-02  2.61188857e-02  1.16753057e-02\n",
      "  2.87649892e-02 -2.72274539e-02  2.91517237e-03 -1.93968732e-02\n",
      " -1.71581260e-03  5.60856685e-02 -6.03185892e-02 -7.34681324e-33\n",
      "  5.56649268e-02 -4.45182249e-02 -1.94608625e-02 -5.73619865e-02\n",
      "  4.67216447e-02  5.81175089e-02  7.20425099e-02 -9.32622794e-03\n",
      "  7.72303790e-02 -7.56574720e-02  4.29571159e-02 -3.26098539e-02\n",
      "  9.90134552e-02  6.71951240e-03  1.02324607e-02  1.86439301e-03\n",
      "  7.17284624e-03  6.70174658e-02 -3.11929379e-02  3.83384675e-02\n",
      "  1.11619264e-01 -6.66052401e-02 -8.17648917e-02 -4.17583957e-02\n",
      "  7.07713962e-02  6.54503927e-02 -6.04699273e-03  1.54561521e-02\n",
      " -5.99458106e-02  2.39035231e-03 -2.27705166e-02  1.77985895e-02\n",
      "  5.86090200e-02  1.28970565e-02  4.99235615e-02 -9.52915475e-03\n",
      "  4.39942256e-02  9.19414219e-03 -3.80155072e-02  3.57572846e-02\n",
      " -9.07232612e-02  4.58527654e-02 -1.18229855e-02  5.30305393e-02\n",
      "  3.44284140e-02 -2.99975574e-02  1.69237591e-02 -3.62147391e-02\n",
      "  2.91725434e-02 -3.11114583e-02 -1.86625344e-03  8.33318606e-02\n",
      " -4.21759747e-02 -6.33497462e-02  1.34147210e-02  8.57500583e-02\n",
      "  7.34120458e-02 -2.24735476e-02  2.33819485e-02  4.36903313e-02\n",
      " -4.21758927e-02  1.91192925e-02  1.92786753e-02 -7.35010803e-02\n",
      " -8.72764923e-03  1.00382067e-01 -1.02755763e-02 -1.55698350e-02\n",
      "  1.42423697e-02 -8.21608827e-02  5.60784712e-03  6.92325120e-04\n",
      " -5.49184531e-02 -7.88011551e-02  4.32350812e-03  2.59050764e-02\n",
      "  9.38346609e-02 -2.21936684e-02 -9.37252194e-02 -2.49240231e-02\n",
      "  3.11001553e-03 -2.02262364e-02 -4.34852354e-02  7.20979199e-02\n",
      " -2.19475534e-02 -2.11764430e-03  1.64529134e-03  3.56443226e-02\n",
      " -4.88147363e-02  9.37773958e-02 -3.57051753e-02 -4.95475568e-02\n",
      "  2.53279116e-02  1.74219161e-02 -1.52247632e-02  7.93432943e-32\n",
      " -2.28514243e-03 -3.18304030e-03 -5.45180738e-02 -2.14533973e-02\n",
      "  3.93818356e-02  7.76835084e-02  1.45601695e-02  3.93408835e-02\n",
      "  3.37172560e-02  6.42797425e-02  7.14004412e-02 -3.83995846e-02\n",
      " -1.76658612e-02  5.99277485e-03  8.40751920e-03 -4.79960404e-02\n",
      " -3.37269418e-02  3.87323536e-02  4.24602740e-02  4.11282144e-02\n",
      " -4.69472334e-02  1.44734783e-02  1.86511222e-02  3.20214592e-03\n",
      " -9.43631306e-03  7.99187645e-02  1.18420990e-02 -1.06994070e-01\n",
      " -4.25159633e-02  3.83082777e-02 -1.36941671e-02  3.78355980e-02\n",
      " -1.19755417e-01 -3.02206762e-02  1.38386956e-03 -3.03875785e-02\n",
      "  1.45649696e-02  3.35933990e-03  1.99320298e-02 -1.85447168e-02\n",
      "  8.96754116e-02  2.52333619e-02 -8.54635052e-03 -2.46082270e-03\n",
      "  1.95091348e-02  2.84078880e-03 -1.05682025e-02  2.13836450e-02\n",
      " -5.95715977e-02 -9.96608101e-03 -2.57614218e-02 -2.44826656e-02\n",
      " -2.45882478e-02  3.14735398e-02  1.12771394e-03 -3.83718163e-02\n",
      " -4.38775010e-02  1.55602135e-02 -5.55873513e-02  1.64175984e-02\n",
      " -3.31647284e-02 -5.86596392e-02 -8.36570710e-02 -8.25228542e-02]\n"
     ]
    }
   ],
   "source": [
    "embeddings_MiniLM = generate_embedding(movies_data, 'MiniLM')\n",
    "embeddings_MiniLM = np.array(embeddings_MiniLM)\n",
    "print(\"MiniLM embeddings shape:\", embeddings_MiniLM.shape)\n",
    "print(\"MiniLM embeddings:\", embeddings_MiniLM[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding movie texts and generating embeddings: 100%|██████████| 631/631 [00:00<00:00, 1285.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoBERTa embeddings shape: (631, 1024)\n",
      "RoBERTa embeddings: [ 0.02298054  0.04175862 -0.01646351 ...  0.01556577 -0.0256803\n",
      "  0.06172808]\n"
     ]
    }
   ],
   "source": [
    "embeddings_roberta = generate_embedding(movies_data, 'roberta')\n",
    "embeddings_roberta = np.array(embeddings_roberta)\n",
    "print(\"RoBERTa embeddings shape:\", embeddings_roberta.shape)\n",
    "print(\"RoBERTa embeddings:\", embeddings_roberta[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e5-large embeddings shape: (631, 1024)\n",
      "e5-large embeddings: [-0.01276984 -0.05366214  0.04731817 ...  0.01435485  0.02704632\n",
      "  0.03876564]\n"
     ]
    }
   ],
   "source": [
    "embeddings_e5_large = generate_embedding(movies_data, 'e5-large')\n",
    "embeddings_e5_large = np.array(embeddings_e5_large)\n",
    "print(\"e5-large embeddings shape:\", embeddings_e5_large.shape)\n",
    "print(\"e5-large embeddings:\", embeddings_e5_large[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create connection to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(database=\"postgres\", host=\"localhost\", user=\"postgres\", password=\"postgres\", port=\"5432\")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "conn.commit()\n",
    "cur.execute(\"CREATE EXTENSION IF NOT EXISTS cube;\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_database():\n",
    "    cur.execute('DROP TABLE IF EXISTS movies')\n",
    "    cur.execute('''\n",
    "        CREATE TABLE movies (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            title TEXT NOT NULL,\n",
    "            actors TEXT,\n",
    "            year INTEGER,\n",
    "            country TEXT,\n",
    "            language TEXT,\n",
    "            duration INTEGER,\n",
    "            summary TEXT,\n",
    "            genre TEXT[],\n",
    "            director TEXT,\n",
    "            scenarists TEXT[],\n",
    "            poster TEXT,\n",
    "            embedding_bart VECTOR(1024),\n",
    "            embedding_gte VECTOR(1024),\n",
    "            embedding_MiniLM VECTOR(384),\n",
    "            embedding_roberta VECTOR(1024),\n",
    "            embedding_e5_large VECTOR(1024)\n",
    "        );\n",
    "    ''')\n",
    "    conn.commit()\n",
    "\n",
    "setup_database()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_movies(movie_data, embeddings_bart, embeddings_gte, embeddings_MiniLM, embeddings_roberta, embeddings_e5_large):\n",
    "    for movie, emb_bart, emb_gte, emb_MiniLM , emb_roberta, emb_e5_large in zip(movie_data, embeddings_bart, embeddings_gte, embeddings_MiniLM, embeddings_roberta, embeddings_e5_large):\n",
    "        # Joining actors into a single string separated by commas\n",
    "        actor_names = ', '.join(movie['actors'])\n",
    "        # Convert list of genres into a PostgreSQL array format\n",
    "        genre_array = '{' + ', '.join([f'\"{g}\"' for g in movie['genre']]) + '}'\n",
    "        # Convert list of scenarists into a PostgreSQL array format\n",
    "        scenarist_array = '{' + ', '.join([f'\"{s}\"' for s in movie['writers']]) + '}'\n",
    "        # Convert embeddings to a string properly formatted as a list\n",
    "        embedding_bart_str = '[' + ', '.join(map(str, emb_bart)) + ']'\n",
    "        embedding_gte_str = '[' + ', '.join(map(str, emb_gte)) + ']'\n",
    "        embedding_MiniLM_str = '[' + ', '.join(map(str, emb_MiniLM)) + ']'\n",
    "        embedding_roberta_str = '[' + ', '.join(map(str, emb_roberta)) + ']'\n",
    "        embedding_e5_large_str = '[' + ', '.join(map(str, emb_e5_large)) + ']'\n",
    "\n",
    "        cur.execute('''\n",
    "            INSERT INTO movies (title, actors, year, country, language, duration, summary, genre, director, scenarists, poster, embedding_bart, embedding_gte, embedding_MiniLM, embedding_roberta, embedding_e5_large)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        ''', (\n",
    "            movie['title'], actor_names, movie['year'], movie['country'], movie['language'],\n",
    "            movie['duration'], movie['summary'], genre_array, movie['director'],\n",
    "            scenarist_array, movie['poster'], embedding_bart_str, embedding_gte_str, embedding_MiniLM_str, embedding_roberta_str, embedding_e5_large_str\n",
    "        ))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_movies(movies_data, embeddings_bart, embeddings_gte, embeddings_MiniLM, embeddings_roberta, embeddings_e5_large)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
